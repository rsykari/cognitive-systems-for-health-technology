{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os, shutil"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 22.  28.]\n",
      " [ 49.  64.]]\n"
     ]
    }
   ],
   "source": [
    "# Creates a graph.\n",
    "a = tf.constant([1.0, 2.0, 3.0, 4.0, 5.0, 6.0], shape=[2, 3], name='a')\n",
    "b = tf.constant([1.0, 2.0, 3.0, 4.0, 5.0, 6.0], shape=[3, 2], name='b')\n",
    "c = tf.matmul(a, b)\n",
    "# Creates a session with log_device_placement set to True.\n",
    "sess = tf.Session(config=tf.ConfigProto(log_device_placement=True))\n",
    "# Runs the op.\n",
    "print(sess.run(c))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Next we create the names for the directories and save them into variables.\n",
    "\n",
    "# Base directory is where the datasets will be created\n",
    "base_dir = 'E:\\\\python_projects\\\\case_2_datasets'\n",
    "\n",
    "# For training set\n",
    "sub_dir = 'train'\n",
    "train_dir = os.path.join(base_dir, sub_dir)\n",
    "train_nosymptoms_dir = os.path.join(base_dir, sub_dir, class1)\n",
    "train_symptoms_dir = os.path.join(base_dir, sub_dir, class2)\n",
    "\n",
    "# For validation set\n",
    "sub_dir = 'validation'\n",
    "validation_dir = os.path.join(base_dir, sub_dir)\n",
    "validation_nosymptoms_dir = os.path.join(base_dir, sub_dir, class1)\n",
    "validation_symptoms_dir = os.path.join(base_dir, sub_dir, class2)\n",
    "\n",
    "# For test set\n",
    "sub_dir = 'test'\n",
    "test_dir = os.path.join(base_dir, sub_dir)\n",
    "test_nosymptoms_dir = os.path.join(base_dir, sub_dir, class1)\n",
    "test_symptoms_dir = os.path.join(base_dir, sub_dir, class2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# If it is the first time running the code, create subfolders for datasets\n",
    "\n",
    "if not(os.path.exists(base_dir)):\n",
    "    print('Creating dataset folders to:', base_dir)\n",
    "    os.mkdir(base_dir)\n",
    "    os.mkdir(train_dir)\n",
    "    os.mkdir(train_nosymptoms_dir)\n",
    "    os.mkdir(train_symptoms_dir)\n",
    "    os.mkdir(validation_dir)\n",
    "    os.mkdir(validation_nosymptoms_dir)\n",
    "    os.mkdir(validation_symptoms_dir)\n",
    "    os.mkdir(test_dir)\n",
    "    os.mkdir(test_nosymptoms_dir)\n",
    "    os.mkdir(test_symptoms_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Splitting train/validation/test sets in 60/20/20 fashion for both nosymptoms and symptoms datasets\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Take 20% out for testing\n",
    "train_nosymptoms_fnames, test_nosymptoms_fnames = train_test_split(nosymptoms_fnames, test_size = 0.2)\n",
    "train_symptoms_fnames, test_symptoms_fnames = train_test_split(symptoms_fnames, test_size = 0.2)\n",
    "\n",
    "# From the remaining 80% take 0.25 (=0.8*0.25 = 20% of total) out for validation\n",
    "train_nosymptoms_fnames, validation_nosymptoms_fnames = train_test_split(train_nosymptoms_fnames, test_size = 0.25)\n",
    "train_symptoms_fnames, validation_symptoms_fnames = train_test_split(train_symptoms_fnames, test_size = 0.25)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Copying the files into the dataset folders\n",
    "\n",
    "# Training set\n",
    "# Disease \n",
    "for fname in train_symptoms_fnames:\n",
    "    src = os.path.join(original_symptoms_dir, fname)\n",
    "    dst = os.path.join(train_symptoms_dir, fname)\n",
    "    shutil.copyfile(src, dst)\n",
    "# Healthy \n",
    "for fname in train_nosymptoms_fnames:\n",
    "    src = os.path.join(original_nosymptoms_dir, fname)\n",
    "    dst = os.path.join(train_nosymptoms_dir, fname)\n",
    "    shutil.copyfile(src, dst)\n",
    "\n",
    "# Validation set\n",
    "# Disease \n",
    "for fname in validation_symptoms_fnames:\n",
    "    src = os.path.join(original_symptoms_dir, fname)\n",
    "    dst = os.path.join(validation_symptoms_dir, fname)\n",
    "    shutil.copyfile(src, dst)\n",
    "# Healthy\n",
    "for fname in validation_nosymptoms_fnames:\n",
    "    src = os.path.join(original_nosymptoms_dir, fname)\n",
    "    dst = os.path.join(validation_nosymptoms_dir, fname)\n",
    "    shutil.copyfile(src, dst)\n",
    "\n",
    "# Test set\n",
    "# Disease\n",
    "for fname in test_symptoms_fnames:\n",
    "    src = os.path.join(original_symptoms_dir, fname)\n",
    "    dst = os.path.join(test_symptoms_dir, fname)\n",
    "    shutil.copyfile(src, dst)\n",
    "# Healthy\n",
    "for fname in test_nosymptoms_fnames:\n",
    "    src = os.path.join(original_nosymptoms_dir, fname)\n",
    "    dst = os.path.join(test_nosymptoms_dir, fname)\n",
    "    shutil.copyfile(src, dst)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Implemented undersampling by removing extra non-symptomatic examples\n",
    "\n",
    "import random\n",
    "\n",
    "train_no_symptom_list = os.listdir('E:\\\\python_projects\\\\case_2_datasets\\\\train\\\\nosymptoms')\n",
    "train_number_of_no_symptoms = len(train_no_symptom_list)\n",
    "\n",
    "train_symptom_list = os.listdir('E:\\\\python_projects\\\\case_2_datasets\\\\train\\\\symptoms')\n",
    "train_number_of_symptoms = len(train_symptom_list)\n",
    "\n",
    "train_remove_count = train_number_of_no_symptoms - train_number_of_symptoms\n",
    "while train_remove_count > 0:\n",
    "    choice = random.choice(os.listdir('E:\\\\python_projects\\\\case_2_datasets\\\\train\\\\nosymptoms'))\n",
    "    os.remove(os.path.join('E:\\\\python_projects\\\\case_2_datasets\\\\train\\\\nosymptoms', choice))\n",
    "    train_remove_count -= 1\n",
    "\n",
    "\n",
    "validation_no_symptom_list = os.listdir('E:\\\\python_projects\\\\case_2_datasets\\\\validation\\\\nosymptoms')\n",
    "validation_number_of_no_symptoms = len(validation_no_symptom_list)\n",
    "\n",
    "validation_symptom_list = os.listdir('E:\\\\python_projects\\\\case_2_datasets\\\\validation\\\\symptoms')\n",
    "validation_number_of_symptoms = len(validation_symptom_list)\n",
    "\n",
    "validation_remove_count = validation_number_of_no_symptoms - validation_number_of_symptoms\n",
    "while validation_remove_count > 0:\n",
    "    choice = random.choice(os.listdir('E:\\\\python_projects\\\\case_2_datasets\\\\validation\\\\nosymptoms'))\n",
    "    os.remove(os.path.join('E:\\\\python_projects\\\\case_2_datasets\\\\validation\\\\nosymptoms', choice))\n",
    "    validation_remove_count -= 1\n",
    "\n",
    "\n",
    "test_no_symptom_list = os.listdir('E:\\\\python_projects\\\\case_2_datasets\\\\test\\\\nosymptoms')\n",
    "test_number_of_no_symptoms = len(test_no_symptom_list)\n",
    "\n",
    "test_symptom_list = os.listdir('E:\\\\python_projects\\\\case_2_datasets\\\\test\\\\symptoms')\n",
    "test_number_of_symptoms = len(test_symptom_list)\n",
    "\n",
    "test_remove_count = test_number_of_no_symptoms - test_number_of_symptoms\n",
    "while test_remove_count > 0:\n",
    "    choice = random.choice(os.listdir('E:\\\\python_projects\\\\case_2_datasets\\\\test\\\\nosymptoms'))\n",
    "    os.remove(os.path.join('E:\\\\python_projects\\\\case_2_datasets\\\\test\\\\nosymptoms', choice))\n",
    "    test_remove_count -= 1\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
